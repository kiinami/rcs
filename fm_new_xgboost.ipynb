{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Francesco1\\miniconda3\\envs\\RecSysFramework\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import *\n",
    "import optuna\n",
    "from Recommenders.Recommender_import_list import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, usermap, itemmap, users = load_data2()\n",
    "data_train, data_val = split_data2(data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-29 17:37:21,387] A new study created in memory with name: P3Beta\n"
     ]
    }
   ],
   "source": [
    "candidate_recommender_study = optuna.create_study(\n",
    "    study_name=\"P3Beta\",\n",
    "    #storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "candidate_recommender = RP3betaRecommender(data_train, verbose=False)\n",
    "candidate_recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = data_train.shape\n",
    "\n",
    "training_dataframe = pd.DataFrame(index=range(0,n_users), columns = [\"ItemID\"])\n",
    "training_dataframe.index.name='UserID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 50\n",
    "\n",
    "for user_id in range(n_users):    \n",
    "    recommendations = candidate_recommender.recommend(user_id, cutoff = cutoff)\n",
    "    training_dataframe.loc[user_id, \"ItemID\"] = recommendations\n",
    "training_dataframe = training_dataframe.explode(\"ItemID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "\n",
    "data_val_coo = sps.coo_matrix(data_val)\n",
    "correct_recommendations = pd.DataFrame({\"UserID\": data_val_coo.row,\n",
    "                                        \"ItemID\": data_val_coo.col})\n",
    "training_dataframe = pd.merge(training_dataframe, correct_recommendations, on=['UserID','ItemID'], how='left', indicator='Exist')\n",
    "training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "training_dataframe.drop(columns = ['Exist'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-29 17:37:37,735] A new study created in memory with name: P3Alpha\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopPopRecommender: URM Detected 220 ( 1.7%) users with no interactions.\n",
      "TopPopRecommender: URM Detected 97 ( 0.4%) items with no interactions.\n",
      "P3alphaRecommender: URM Detected 220 ( 1.7%) users with no interactions.\n",
      "P3alphaRecommender: URM Detected 97 ( 0.4%) items with no interactions.\n",
      "P3alphaRecommender: Similarity column 22222 (100.0%), 3175.01 column/sec. Elapsed time 7.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-29 17:37:46,308] A new study created in memory with name: ItemKNNCF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: URM Detected 220 ( 1.7%) users with no interactions.\n",
      "ItemKNNCFRecommender: URM Detected 97 ( 0.4%) items with no interactions.\n",
      "Similarity column 22222 (100.0%), 8723.61 column/sec. Elapsed time 2.55 sec\n"
     ]
    }
   ],
   "source": [
    "topPop = TopPop(data_train)\n",
    "topPop.fit()\n",
    "\n",
    "p3alpha_study = optuna.create_study(\n",
    "    study_name=\"P3Alpha\",\n",
    "    #storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "p3alpha = P3alphaRecommender(data_train)\n",
    "p3alpha.fit()\n",
    "\n",
    "#easer_study = optuna.create_study(\n",
    "#    study_name=\"Easer\",\n",
    "#    #storage=get_database_url(),\n",
    "#    load_if_exists=True,\n",
    "#    direction=\"maximize\",\n",
    "#)\n",
    "#easer = EASE_R_Recommender(data_train)\n",
    "#easer.fit(topK=72, l2_norm=36.47305040353163)\n",
    "\n",
    "itemknncf_study = optuna.create_study(\n",
    "    study_name=\"ItemKNNCF\",\n",
    "    #storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "itemknncf = ItemKNNCFRecommender(data_train)\n",
    "itemknncf.fit()\n",
    "\n",
    "\n",
    "other_algorithms = {\n",
    "    \"TopPop\": topPop,\n",
    "    \"P3alpha\": p3alpha,\n",
    "    #\"Easer\": easer,\n",
    "    \"ItemKNNCF\": itemknncf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = training_dataframe.set_index('UserID')\n",
    "\n",
    "for user_id in range(n_users):  \n",
    "    for rec_label, rec_instance in other_algorithms.items():\n",
    "        item_list = training_dataframe.loc[user_id, \"ItemID\"].values.tolist()\n",
    "        all_item_scores = rec_instance._compute_item_score([user_id], items_to_compute = item_list)\n",
    "        training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list] \n",
    "\n",
    "training_dataframe = training_dataframe.reset_index()\n",
    "training_dataframe = training_dataframe.rename(columns = {\"index\": \"UserID\"})\n",
    "\n",
    "item_popularity = np.ediff1d(sps.csc_matrix(data_train).indptr)\n",
    "training_dataframe['item_popularity'] = item_popularity[training_dataframe[\"ItemID\"].values.astype(int)]\n",
    "user_popularity = np.ediff1d(sps.csr_matrix(data_train).indptr)\n",
    "training_dataframe['user_profile_len'] = user_popularity[training_dataframe[\"UserID\"].values.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = training_dataframe.set_index('ItemID')\n",
    "training_dataframe = training_dataframe.reset_index()\n",
    "training_dataframe = training_dataframe.rename(columns = {\"index\": \"ItemID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = training_dataframe.groupby(\"UserID\").size().values\n",
    "train_recs = training_dataframe.drop(columns=[\"Label\"])\n",
    "train_labs = training_dataframe[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-29 17:38:08,204] A new study created in memory with name: XGBoost(P3Beta, TopPop, P3alpha, Easer, ItemKNNCF)\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"XGBoost(P3Beta, TopPop, P3alpha, Easer, ItemKNNCF)\",\n",
    "    #storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(data_train, train_recs, XGB_model, training_dataframe, data_test: sp.csr_matrix, recommendation_length: int = 10):\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "\n",
    "    num_users = data_train.shape[0]\n",
    "\n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = data_test.indptr[user_id]\n",
    "        user_profile_end = data_test.indptr[user_id+1]\n",
    "\n",
    "        relevant_items = data_test.indices[user_profile_start:user_profile_end]\n",
    "\n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        predict = train_recs[train_recs[\"UserID\"] == user_id]\n",
    "        predictions = XGB_model.predict(predict)\n",
    "        user_ids = predict[\"UserID\"].values\n",
    "        item_ids = predict[\"ItemID\"].values\n",
    "        predictions = pd.DataFrame({\"UserID\": user_ids, \"ItemID\": item_ids, \"Predictions\": predictions})\n",
    "        predictions = predictions.sort_values(by=\"Predictions\", ascending=False)\n",
    "        recommendations = np.array(predictions[\"ItemID\"].values[:recommendation_length])\n",
    "\n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "\n",
    "        num_users_evaluated += 1\n",
    "\n",
    "\n",
    "    accum_precision /= max(num_users_evaluated, 1)\n",
    "    accum_recall /= max(num_users_evaluated, 1)\n",
    "    accum_map /=  max(num_users_evaluated, 1)\n",
    "\n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-29 18:08:44,535] Trial 4 finished with value: 0.043258269653554615 and parameters: {'objective': 'rank:map', 'n_estimators': 489, 'learning_rate': 0.018590811418379614, 'reg_alpha': 0.003700046939843544, 'reg_lambda': 0.045807529399430995, 'max_depth': 2, 'max_leaves': 9, 'grow_policy': 'depthwise', 'booster': 'gblinear'}. Best is trial 2 with value: 0.05127384661844544.\n",
      "[I 2023-12-29 18:10:22,338] Trial 5 finished with value: 0.0682245791815283 and parameters: {'objective': 'rank:map', 'n_estimators': 70, 'learning_rate': 0.0008765542961329935, 'reg_alpha': 0.012021960865902171, 'reg_lambda': 0.0004814250009694544, 'max_depth': 4, 'max_leaves': 7, 'grow_policy': 'lossguide', 'booster': 'dart'}. Best is trial 5 with value: 0.0682245791815283.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "def objective(trial):\n",
    "    objective = trial.suggest_categorical(\"objective\", [\"rank:ndcg\", \"rank:map\", \"rank:pairwise\"])\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 5, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-4, 1e-1, log=True)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 1, 10)\n",
    "    grow_policy = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n",
    "\n",
    "    XGB_model = XGBRanker(\n",
    "        tree_method=\"hist\",\n",
    "        objective=objective,\n",
    "        n_estimators=int(n_estimators),\n",
    "        random_state=None,\n",
    "        learning_rate=learning_rate,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        max_depth=int(max_depth),\n",
    "        max_leaves=int(max_leaves),\n",
    "        grow_policy=grow_policy,\n",
    "        booster=booster,\n",
    "        verbosity=0, # 2 if self.verbose else 0,\n",
    "    )\n",
    "    XGB_model.fit(\n",
    "        train_recs,\n",
    "        train_labs,\n",
    "        group=groups,\n",
    "        verbose=False\n",
    "    )\n",
    "    _, _, ev_map, _, _ = evaluator(data_train, train_recs, XGB_model, training_dataframe, data_val)\n",
    "    \n",
    "    return ev_map\n",
    "\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'rank:map',\n",
       " 'n_estimators': 70,\n",
       " 'learning_rate': 0.0008765542961329935,\n",
       " 'reg_alpha': 0.012021960865902171,\n",
       " 'reg_lambda': 0.0004814250009694544,\n",
       " 'max_depth': 4,\n",
       " 'max_leaves': 7,\n",
       " 'grow_policy': 'lossguide',\n",
       " 'booster': 'dart'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampare solo le righe con almeno un NaN\n",
    "for row_index in data_val:\n",
    "    if np.isnan(row_index.data).any():\n",
    "        print(row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGB_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#data_train = data_train.fillna(0)  # O sostituisci con un valore appropriato\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#data_val = data_val.fillna(0)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m recommender \u001b[38;5;241m=\u001b[39m XGBRanker(\u001b[43mXGB_model\u001b[49m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m recommender\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudy\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGB_model' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "import pandas as pd\n",
    "\n",
    "#data_train = data_train.fillna(0)  # O sostituisci con un valore appropriato\n",
    "#data_val = data_val.fillna(0)\n",
    "\n",
    "recommender = XGBRanker(XGB_model, verbose=False)\n",
    "recommender.fit(**study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission2(recommender, users, usermap, itemmap, data_train):\n",
    "    \n",
    "    toppoprecommender = TopPop(data_train)\n",
    "    toppoprecommender.fit()\n",
    "    \n",
    "    with open('data/results.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['user_id', 'item_list'])\n",
    "        for user_id in users:\n",
    "            try:\n",
    "                item_list = recommender.recommend(user_id, cutoff=10)\n",
    "                item_list = [itemmap[i] for i in item_list]\n",
    "                writer.writerow([usermap[user_id], ' '.join(map(str, item_list))])\n",
    "            except IndexError:\n",
    "                item_list = toppoprecommender.recommend(0, cutoff=10)\n",
    "                item_list = [itemmap[i] for i in item_list]\n",
    "                writer.writerow([usermap[user_id], ' '.join(map(str, item_list))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submission2(\u001b[43mrecommender\u001b[49m, users, usermap, itemmap, data_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recommender' is not defined"
     ]
    }
   ],
   "source": [
    "submission2(recommender, users, usermap, itemmap, data_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysFramework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
