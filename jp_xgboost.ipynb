{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\francesco\\miniconda3\\envs\\RecSysFramework\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import *\n",
    "import optuna\n",
    "from Recommenders.Recommender_import_list import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, usermap, itemmap, users = load_data2()\n",
    "data_train, data_val = split_data2(data, 0.2)\n",
    "data_train_val = data_train + data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-31 18:17:13,106] A new study created in memory with name: P3Beta\n"
     ]
    }
   ],
   "source": [
    "candidate_recommender_study = optuna.create_study(\n",
    "    study_name=\"P3Beta\",\n",
    "    #storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "candidate_recommender = RP3betaRecommender(data_train_val, verbose=False)\n",
    "candidate_recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12633</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12634</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12635</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12636</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12638 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID\n",
       "UserID       \n",
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         NaN\n",
       "...       ...\n",
       "12633     NaN\n",
       "12634     NaN\n",
       "12635     NaN\n",
       "12636     NaN\n",
       "12637     NaN\n",
       "\n",
       "[12638 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_items = data_train.shape\n",
    "\n",
    "training_dataframe = pd.DataFrame(index=range(0,n_users), columns = [\"ItemID\"])\n",
    "training_dataframe.index.name='UserID'\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>19760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>16596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>19019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12637</th>\n",
       "      <td>21632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID\n",
       "UserID       \n",
       "0       22146\n",
       "0         674\n",
       "0       15344\n",
       "0         587\n",
       "0        2843\n",
       "...       ...\n",
       "12637   19760\n",
       "12637   16596\n",
       "12637   19019\n",
       "12637    1478\n",
       "12637   21632\n",
       "\n",
       "[631900 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = 50\n",
    "\n",
    "for user_id in range(n_users):    \n",
    "    recommendations = candidate_recommender.recommend(user_id, cutoff = cutoff, remove_seen_flag=True)\n",
    "    training_dataframe.loc[user_id, \"ItemID\"] = recommendations\n",
    "training_dataframe = training_dataframe.explode(\"ItemID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID  ItemID\n",
      "0        0      18\n",
      "1        0      20\n",
      "2        0      30\n",
      "3        0      34\n",
      "4        0      36\n",
      "5        0      39\n",
      "6        0      43\n",
      "7        1       6\n",
      "8        1      51\n",
      "9        1      55\n",
      "10       1      62\n",
      "11       1      68\n",
      "12       1      69\n",
      "13       1      76\n",
      "14       1      77\n",
      "15       1      78\n",
      "16       2      80\n",
      "17       2      81\n",
      "18       3      10\n",
      "19       3      87\n",
      "20       3      89\n",
      "21       3      91\n",
      "22       3      93\n",
      "23       3      95\n",
      "24       3      96\n",
      "25       3      97\n",
      "26       3     106\n",
      "27       3     111\n",
      "28       3     113\n",
      "29       4      44\n",
      "30       4     118\n",
      "31       4     122\n",
      "32       4     128\n",
      "33       4     147\n",
      "34       4     156\n",
      "35       4     161\n",
      "36       4     165\n",
      "37       4     170\n",
      "38       4     174\n",
      "39       4     175\n",
      "40       4     177\n",
      "41       4     185\n",
      "42       5      51\n",
      "43       5     193\n",
      "44       5     196\n",
      "45       5     197\n",
      "46       6     204\n",
      "47       7      44\n",
      "48       7     117\n",
      "49       7     206\n",
      "    UserID ItemID  Label      Exist\n",
      "20       0  16216  False  left_only\n",
      "21       0   2023  False  left_only\n",
      "22       0  21717  False  left_only\n",
      "23       0   4802  False  left_only\n",
      "24       0  14249  False  left_only\n",
      "25       0  16847  False  left_only\n",
      "26       0  12836  False  left_only\n",
      "27       0  18729  False  left_only\n",
      "28       0  20159  False  left_only\n",
      "29       0  20160  False  left_only\n",
      "30       0   4512  False  left_only\n",
      "31       0  13326  False  left_only\n",
      "32       0  20208  False  left_only\n",
      "33       0  12897  False  left_only\n",
      "34       0  20955  False  left_only\n",
      "35       0  21400  False  left_only\n",
      "36       0  19566  False  left_only\n",
      "37       0   1163  False  left_only\n",
      "38       0  19017  False  left_only\n",
      "39       0   1167  False  left_only\n",
      "40       0  20178  False  left_only\n",
      "41       0    731  False  left_only\n",
      "42       0  18491  False  left_only\n",
      "43       0  16786  False  left_only\n",
      "44       0  13840  False  left_only\n",
      "45       0   2755  False  left_only\n",
      "46       0   3708  False  left_only\n",
      "47       0   8736  False  left_only\n",
      "48       0  22069  False  left_only\n",
      "49       0   1476  False  left_only\n",
      "50       1   9728  False  left_only\n",
      "51       1   2548  False  left_only\n",
      "52       1     68  False  left_only\n",
      "53       1     89  False  left_only\n",
      "54       1    227  False  left_only\n",
      "55       1    841  False  left_only\n",
      "56       1    517  False  left_only\n",
      "57       1   2612  False  left_only\n",
      "58       1    812  False  left_only\n",
      "59       1  17053  False  left_only\n",
      "60       1    189  False  left_only\n",
      "61       1   5564  False  left_only\n",
      "62       1    808  False  left_only\n",
      "63       1   5256  False  left_only\n",
      "64       1   5682  False  left_only\n",
      "65       1  18653  False  left_only\n",
      "66       1    284  False  left_only\n",
      "67       1     84  False  left_only\n",
      "68       1  14614  False  left_only\n",
      "69       1    285  False  left_only\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sps\n",
    "\n",
    "data_val_coo = sps.coo_matrix(data_val)\n",
    "correct_recommendations = pd.DataFrame({\"UserID\": data_val_coo.row,\n",
    "                                        \"ItemID\": data_val_coo.col})\n",
    "training_dataframe = pd.merge(training_dataframe, correct_recommendations, on=['UserID','ItemID'], how='left', indicator='Exist')\n",
    "training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "training_dataframe.drop(columns = ['Exist'], inplace=True)\n",
    "#training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-31 16:33:48,133] Using an existing study with name 'P3Alpha' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3alphaRecommender: Similarity column 22222 (100.0%), 3058.59 column/sec. Elapsed time 7.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-31 16:33:57,152] Using an existing study with name 'Easer' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE_R_Recommender: Fitting model... \n",
      "EASE_R_Recommender: Fitting model... done in 3.29 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-31 16:37:32,112] Using an existing study with name 'ItemKNNCF' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 22222 (100.0%), 8859.04 column/sec. Elapsed time 2.51 sec\n"
     ]
    }
   ],
   "source": [
    "topPop = TopPop(data_train_val)\n",
    "topPop.fit()\n",
    "\n",
    "p3alpha_study = optuna.create_study(\n",
    "    study_name=\"P3Alpha\",\n",
    "    storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "p3alpha = P3alphaRecommender(data_train_val)\n",
    "p3alpha.fit(**p3alpha_study.best_params)\n",
    "\n",
    "easer_study = optuna.create_study(\n",
    "    study_name=\"Easer\",\n",
    "    storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "easer = EASE_R_Recommender(data_train_val)\n",
    "easer.fit(**easer_study.best_params)\n",
    "\n",
    "itemknncf_study = optuna.create_study(\n",
    "    study_name=\"ItemKNNCF\",\n",
    "    storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "itemknncf = ItemKNNCFRecommender(data_train_val)\n",
    "itemknncf.fit(**itemknncf_study.best_params)\n",
    "\n",
    "\n",
    "other_algorithms = {\n",
    "    \"TopPop\": topPop,\n",
    "    \"P3alpha\": p3alpha,\n",
    "    \"Easer\": easer,\n",
    "    \"ItemKNNCF\": itemknncf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = training_dataframe.set_index('UserID')\n",
    "\n",
    "for user_id in range(n_users):  \n",
    "    for rec_label, rec_instance in other_algorithms.items():\n",
    "        item_list = training_dataframe.loc[user_id, \"ItemID\"].values.tolist()\n",
    "        all_item_scores = rec_instance._compute_item_score([user_id], items_to_compute = item_list)\n",
    "        training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list] \n",
    "\n",
    "training_dataframe = training_dataframe.reset_index()\n",
    "training_dataframe = training_dataframe.rename(columns = {\"index\": \"UserID\"})\n",
    "\n",
    "item_popularity = np.ediff1d(sps.csc_matrix(data_train).indptr)\n",
    "training_dataframe['item_popularity'] = item_popularity[training_dataframe[\"ItemID\"].values.astype(int)]\n",
    "user_popularity = np.ediff1d(sps.csr_matrix(data_train).indptr)\n",
    "training_dataframe['user_profile_len'] = user_popularity[training_dataframe[\"UserID\"].values.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = training_dataframe.set_index('ItemID')\n",
    "training_dataframe = training_dataframe.reset_index()\n",
    "training_dataframe = training_dataframe.rename(columns = {\"index\": \"ItemID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = training_dataframe.groupby(\"UserID\").size().values\n",
    "train_recs = training_dataframe.drop(columns=[\"Label\"])\n",
    "train_labs = training_dataframe[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-31 16:38:53,559] Using an existing study with name 'XGBoost(P3Beta, TopPop, P3alpha, Easer, ItemKNNCF)' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"XGBoost(P3Beta, TopPop, P3alpha, Easer, ItemKNNCF)\",\n",
    "    storage=get_database_url(),\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(data_train, train_recs, XGB_model, training_dataframe, data_test: sp.csr_matrix, recommendation_length: int = 10):\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "\n",
    "    num_users = data_train.shape[0]\n",
    "\n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = data_test.indptr[user_id]\n",
    "        user_profile_end = data_test.indptr[user_id+1]\n",
    "\n",
    "        relevant_items = data_test.indices[user_profile_start:user_profile_end]\n",
    "\n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "        \n",
    "        predict = train_recs[train_recs[\"UserID\"] == user_id]\n",
    "        predictions = XGB_model.predict(predict)\n",
    "        user_ids = predict[\"UserID\"].values\n",
    "        item_ids = predict[\"ItemID\"].values\n",
    "        predictions = pd.DataFrame({\"UserID\": user_ids, \"ItemID\": item_ids, \"Predictions\": predictions})\n",
    "        predictions = predictions.sort_values(by=\"Predictions\", ascending=False)\n",
    "        recommendations = np.array(predictions[\"ItemID\"].values[:recommendation_length])\n",
    "\n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "\n",
    "        num_users_evaluated += 1\n",
    "\n",
    "\n",
    "    accum_precision /= max(num_users_evaluated, 1)\n",
    "    accum_recall /= max(num_users_evaluated, 1)\n",
    "    accum_map /=  max(num_users_evaluated, 1)\n",
    "\n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "def objective(trial):\n",
    "    objective = trial.suggest_categorical(\"objective\", [\"rank:ndcg\", \"rank:map\", \"rank:pairwise\"])\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 5, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-4, 1e-1, log=True)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-4, 1e-1, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 1, 10)\n",
    "    grow_policy = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    booster = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"])\n",
    "\n",
    "    XGB_model = XGBRanker(\n",
    "        tree_method=\"hist\",\n",
    "        objective=objective,\n",
    "        n_estimators=int(n_estimators),\n",
    "        random_state=None,\n",
    "        learning_rate=learning_rate,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        max_depth=int(max_depth),\n",
    "        max_leaves=int(max_leaves),\n",
    "        grow_policy=grow_policy,\n",
    "        booster=booster,\n",
    "        verbosity=0, # 2 if self.verbose else 0,\n",
    "    )\n",
    "    XGB_model.fit(\n",
    "        train_recs,\n",
    "        train_labs,\n",
    "        group=groups,\n",
    "        verbose=False\n",
    "    )\n",
    "    _, _, ev_map, _, _ = evaluator(data_train, train_recs, XGB_model, training_dataframe, data_val)\n",
    "    \n",
    "    return ev_map\n",
    "\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.09958690670411639,\n",
       "          max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "          max_delta_step=None, max_depth=7, max_leaves=10,\n",
       "          min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "          multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "          num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.09958690670411639,\n",
       "          max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "          max_delta_step=None, max_depth=7, max_leaves=10,\n",
       "          min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "          multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "          num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster='gbtree', callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy='lossguide', importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.09958690670411639,\n",
       "          max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "          max_delta_step=None, max_depth=7, max_leaves=10,\n",
       "          min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "          multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "          num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "XGB_model = XGBRanker(\n",
    "    **study.best_params,\n",
    "    verbosity=0, # 2 if self.verbose else 0,\n",
    "    enable_categorical=True,\n",
    ")\n",
    "XGB_model.fit(\n",
    "    train_recs,\n",
    "    train_labs,\n",
    "    group=groups,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission2(train_recs, XGB_model, users, usermap, itemmap, data_train_val):\n",
    "    \n",
    "    toppoprecommender = TopPop(data_train_val)\n",
    "    toppoprecommender.fit()\n",
    "    \n",
    "    with open('data/results.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['user_id', 'item_list'])\n",
    "        for user_id in users:\n",
    "            predict = train_recs[train_recs[\"UserID\"] == user_id]\n",
    "            user_ids = predict[\"UserID\"].values\n",
    "            item_ids = predict[\"ItemID\"].values\n",
    "            predictions = XGB_model.predict(predict)\n",
    "            if not list(predictions):\n",
    "                predictions = toppoprecommender.recommend(0, cutoff = 10)\n",
    "                item_list = [itemmap[i] for i in predictions]\n",
    "                writer.writerow([usermap[user_id], ' '.join(map(str, item_list))])\n",
    "                continue\n",
    "            predictions = pd.DataFrame({\"UserID\": user_ids, \"ItemID\": item_ids, \"Predictions\": predictions.ravel()})\n",
    "            predictions = predictions.sort_values(by=\"Predictions\", ascending=False)\n",
    "            recommendations = np.array(predictions[\"ItemID\"].values[:10])\n",
    "            item_list = [itemmap[i] for i in recommendations]\n",
    "            writer.writerow([usermap[user_id], ' '.join(map(str, item_list))])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2(train_recs, XGB_model, users, usermap, itemmap, data_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSysFramework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
